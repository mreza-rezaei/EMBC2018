{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of LSTM with 62 nodes and 62 bim before"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### importing what we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#%matplotlib inline\n",
    "# %pylab osx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling1D,UpSampling1D,Reshape,Conv1D\n",
    "import scipy.io as spio\n",
    "import os\n",
    "import pickle\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, TimeDistributed, Bidirectional, Input,LSTM,GRU,ConvLSTM2D\n",
    "from keras.utils.test_utils import keras_test\n",
    "# Some additional libraries which we'll use just\n",
    "# to produce some visualizations of our training\n",
    "\n",
    "import IPython.display as ipyd\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Function that creates the covariate matrix of neural activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########## R-squared (R2) ##########\n",
    "\n",
    "def get_R2(y_test,y_test_pred):\n",
    "\n",
    "    \"\"\"\n",
    "    Function to get R2\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_test - the true outputs (a matrix of size number of examples x number of outputs)\n",
    "    y_test_pred - the predicted outputs (a matrix of size number of examples x number of outputs)\n",
    "    Returns\n",
    "    -------\n",
    "    R2_array: An array of R2s for each output\n",
    "    \"\"\"\n",
    "\n",
    "    y_mean=np.mean(y_test[:,1])\n",
    "    x_mean=np.mean(y_test[:,0])\n",
    "    \n",
    "    x=y_test[:,0]-x_mean\n",
    "    y=y_test[:,1]-y_mean\n",
    "    \n",
    "    e2x=(y_test_pred[:,0]-y_test[:,0])**2\n",
    "    e2y=(y_test_pred[:,1]-y_test[:,1])**2\n",
    "    \n",
    "    R2=1-np.sum(e2x+e2y)/np.sum(x+y)\n",
    "    return R2 #Return an array of R2s\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def distance2(p0,p1):\n",
    "    \n",
    "    return ((p0[0] - p1[0])**2 + (p0[1] - p1[1])**2)\n",
    "\n",
    "def distance(p0,p1):\n",
    "    \n",
    "    return ((p0 - p1)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###$$ GET_SPIKES_WITH_HISTORY #####\n",
    "def get_spikes_with_history(neural_data,bins_before,bins_after,bins_current=1):\n",
    "    \"\"\"\n",
    "   \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    neural_data: a matrix of size \"number of time bins\" x \"number of neurons\"\n",
    "        the number of spikes in each time bin for each neuron\n",
    "    bins_before: integer\n",
    "        How many bins of neural data prior to the output are used for decoding\n",
    "    bins_after: integer\n",
    "        How many bins of neural data after the output are used for decoding\n",
    "    bins_current: 0 or 1, optional, default=1\n",
    "        Whether to use the concurrent time bin of neural data for decoding\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X: a matrix of size \"number of total time bins\" x \"number of surrounding time bins used for prediction\" x \"number of neurons\"\n",
    "        For every time bin, there are the firing rates of all neurons from the specified number of time bins before (and after)\n",
    "    \"\"\"\n",
    "\n",
    "    num_examples=neural_data.shape[0] #Number of total time bins we have neural data for\n",
    "    num_neurons=neural_data.shape[1] #Number of neurons\n",
    "    surrounding_bins=bins_before+bins_after+bins_current #Number of surrounding time bins used for prediction\n",
    "    X=np.empty([num_examples,surrounding_bins,num_neurons]) #Initialize covariate matrix with NaNs\n",
    "    X[:] = 0\n",
    "    #Loop through each time bin, and collect the spikes occurring in surrounding time bins\n",
    "    #Note that the first \"bins_before\" and last \"bins_after\" rows of X will remain filled with NaNs, since they don't get filled in below.\n",
    "    #This is because, for example, we cannot collect 10 time bins of spikes before time bin 8\n",
    "    start_idx=0\n",
    "    for i in range(num_examples-bins_before-bins_after): #The first bins_before and last bins_after bins don't get filled in\n",
    "        end_idx=start_idx+surrounding_bins; #The bins of neural data we will be including are between start_idx and end_idx (which will have length \"surrounding_bins\")\n",
    "        X[i+bins_before,:,:]=neural_data[start_idx:end_idx,:]#Put neural data from surrounding bins in X, starting at row \"bins_before\"\n",
    "        start_idx=start_idx+1;\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create dataset for train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (23209, 62, 62)\n",
      "Train labels shape:  (23209, 2)\n",
      "Test data shape:  (4095, 62, 62)\n",
      "Test labels shape:  (4095, 2)\n"
     ]
    }
   ],
   "source": [
    "bins_before=61 #How many bins of neural data prior to the output are used for decoding\n",
    "bins_current=1 #Whether to use concurrent time bin of neural data\n",
    "bins_after=0 #How many bins of neural data after the output are used for decoding\n",
    "\n",
    "path2='MS_Train_sub4.mat'\n",
    "mat=spio.loadmat(path2,squeeze_me=True)\n",
    "x_data0=mat['MSTrain'][:,1:63].astype('float32')\n",
    "y_data0=mat['MSTrain'][:,63:65].astype('float32')\n",
    "\n",
    "x_data1=mat['MSTest'][:,1:63].astype('float32')\n",
    "y_data1=mat['MSTest'][:,63:65].astype('float32')\n",
    "\n",
    "\n",
    "x_data=np.concatenate((x_data0,x_data1),axis=0)\n",
    "y_data=np.concatenate((y_data0,y_data1),axis=0)\n",
    "\n",
    "\n",
    "X=get_spikes_with_history(x_data,bins_before,bins_after,bins_current)\n",
    "  \n",
    "y_data2=np.divide(y_data-np.mean(y_data,axis=0),np.std(y_data,axis=0))\n",
    "X_train=X[0:x_data.shape[0]-x_data1.shape[0]]\n",
    "\n",
    "y_train=y_data2[0:x_data.shape[0]-x_data1.shape[0]]\n",
    "X_test=X[x_data.shape[0]-x_data1.shape[0]:x_data.shape[0]]\n",
    "y_test=y_data[x_data.shape[0]-x_data1.shape[0]:x_data.shape[0]]\n",
    "print ('Train data shape: ', X_train.shape)\n",
    "print ('Train labels shape: ', y_train.shape)\n",
    "print ('Test data shape: ', X_test.shape)\n",
    "print ('Test labels shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " model=Sequential() #Declare model\n",
    "        #Add recurrent layer\n",
    "model.add(LSTM(62,input_shape=(X_train.shape[1],X_train.shape[2]),activation='tanh',name='LSTM_layer')) #Within recurrent layer, include dropout\n",
    "\n",
    "model.add(Dense(y_train.shape[1],name='output_layer'))\n",
    "#Fit model (and set fitting parameters)\n",
    "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='mse',\n",
    "              optimizer=opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load pre trained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path='saved_models/LSTM62PB60.h5'\n",
    "model.load_weights(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate Test Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test time=2.246270\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import timeit\n",
    "\n",
    "start = timeit.default_timer()\n",
    "\n",
    "#Get predictions\n",
    "y_valid_predicted_lstm=model.predict(X_test)\n",
    "\n",
    "y_predic=y_valid_predicted_lstm*np.std(y_data,axis=0)+np.mean(y_data,axis=0)\n",
    "\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "\n",
    "print('test time=%f'% (stop - start) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate RMSE and 2d distance for X,Y Test path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Estmation X=11.733229\n",
      "RMSE Estmation Y=6.259460\n",
      "2D Distance=13.298478\n"
     ]
    }
   ],
   "source": [
    "rmsX=np.zeros(y_test.shape[0])\n",
    "rmsY=np.zeros(y_test.shape[0])\n",
    "a=np.zeros(y_test.shape[0])\n",
    "for i in range(0,y_test.shape[0]):\n",
    "    rmsX[i] = np.mean(distance(y_test[i,0], y_predic[i,0]))\n",
    "    rmsY[i] = np.mean(distance(y_test[i,1], y_predic[i,1]))\n",
    "    a[i]=distance2(y_test[i,:], y_predic[i,:])\n",
    "rmsX=np.sqrt(np.mean(rmsX))\n",
    "rmsY=np.sqrt(np.mean(rmsY))\n",
    "b=np.sqrt(np.mean(a))\n",
    "print('RMSE Estmation X=%f'%rmsX)\n",
    "\n",
    "print('RMSE Estmation Y=%f'%rmsY)\n",
    "print('2D Distance=%f'%b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot and save prediction Y test path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(num=None, figsize=(12, 6))\n",
    "\n",
    "plt1=plt.plot(y_predic[0:,1],'b',label=\"EstimatedTestPath-Y\")\n",
    "\n",
    "\n",
    "plt.plot(y_test[0:,1],'r',label=\"TestPath-Y\")\n",
    "\n",
    "plt.legend(loc=4)\n",
    "plt.title('Estimate position Y with RMSE=%f'%rmsY)\n",
    "plt.savefig('EstimatedTestPath-Y.png',format='png', dpi=1000,transparent=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
